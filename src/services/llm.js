/**
 * ë©€í‹° LLM ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
 * OpenAIì™€ Claudeë¥¼ ì§€ì›í•˜ëŠ” í†µí•© LLM ì„œë¹„ìŠ¤
 */
export class LLMService {
  constructor(provider = 'openai', config = {}) {
    this.provider = provider;
    this.config = config;
    this.useMock = config.useMock || false;
  }

  /**
   * AI ì‘ë‹µ ìƒì„±
   * @param {string} userMessage - ì‚¬ìš©ì ë©”ì‹œì§€
   * @param {Array} conversationHistory - ëŒ€í™” ê¸°ë¡
   * @param {string} systemPrompt - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
   * @param {Object} options - ì¶”ê°€ ì˜µì…˜
   * @returns {Promise<string>} AI ì‘ë‹µ
   */
  async generateResponse(userMessage, conversationHistory = [], systemPrompt = '', options = {}) {
    if (!userMessage || typeof userMessage !== 'string') {
      throw new Error('User message is required and must be a string');
    }

    // Mock ì‘ë‹µ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
    if (this.useMock) {
      return this.generateMockResponse();
    }

    try {
      switch (this.provider) {
        case 'openai':
          return await this.generateOpenAIResponse(userMessage, conversationHistory, systemPrompt, options);
        case 'claude':
          return await this.generateClaudeResponse(userMessage, conversationHistory, systemPrompt, options);
        default:
          throw new Error(`Unsupported LLM provider: ${this.provider}`);
      }
    } catch (error) {
      console.error(`${this.provider} API error:`, error);
      throw new Error(`${this.provider} API request failed: ${error.message}`);
    }
  }

  /**
   * OpenAI API ì‘ë‹µ ìƒì„± (Vercel Proxyë¥¼ í†µí•´)
   */
  async generateOpenAIResponse(userMessage, conversationHistory, systemPrompt, options) {
    const messages = this.buildMessages(userMessage, conversationHistory, systemPrompt);

    // Vercel Proxyë¥¼ í†µí•´ OpenAI API í˜¸ì¶œ
    const response = await fetch('https://buddy-vercel-proxy.vercel.app/api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        apiUrl: 'https://api.openai.com/v1/chat/completions',
        apiKey: this.config.openaiApiKey,
        model: options.model || 'gpt-4o-mini',
        messages,
        max_tokens: options.maxTokens || 1000,
        temperature: options.temperature || 0.7,
        top_p: options.topP || 1,
        frequency_penalty: options.frequencyPenalty || 0,
        presence_penalty: options.presencePenalty || 0,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
      throw new Error(`HTTP ${response.status}: ${errorData.error?.message || 'API request failed'}`);
    }

    const data = await response.json();
    return this.extractResponseContent(data);
  }

  /**
   * Claude API ì‘ë‹µ ìƒì„±
   */
  async generateClaudeResponse(userMessage, conversationHistory, systemPrompt, options) {
    const messages = this.buildClaudeMessages(userMessage, conversationHistory, systemPrompt);

    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': this.config.claudeApiKey,
        'anthropic-version': '2023-06-01',
      },
      body: JSON.stringify({
        model: options.model || 'claude-3-sonnet-20240229',
        messages,
        max_tokens: options.maxTokens || 1000,
        temperature: options.temperature || 0.7,
        top_p: options.topP || 1,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
      throw new Error(`HTTP ${response.status}: ${errorData.error?.message || 'API request failed'}`);
    }

    const data = await response.json();
    return this.extractClaudeResponseContent(data);
  }

  /**
   * ë©”ì‹œì§€ ë°°ì—´ êµ¬ì„± (OpenAI í˜•ì‹)
   */
  buildMessages(userMessage, conversationHistory, systemPrompt) {
    const messages = [];

    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    if (systemPrompt) {
      messages.push({
        role: 'system',
        content: systemPrompt,
      });
    }

    // ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ìµœê·¼ 8ê°œ ë©”ì‹œì§€ë§Œ)
    const recentHistory = conversationHistory.slice(-8);
    messages.push(...recentHistory);

    // í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    messages.push({
      role: 'user',
      content: userMessage,
    });

    return messages;
  }

  /**
   * ë©”ì‹œì§€ ë°°ì—´ êµ¬ì„± (Claude í˜•ì‹)
   */
  buildClaudeMessages(userMessage, conversationHistory, systemPrompt) {
    const messages = [];

    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” ë³„ë„ í•„ë“œë¡œ ì „ë‹¬
    const systemMessage = systemPrompt || '';

    // ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ìµœê·¼ 8ê°œ ë©”ì‹œì§€ë§Œ)
    const recentHistory = conversationHistory.slice(-8);
    messages.push(...recentHistory);

    // í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    messages.push({
      role: 'user',
      content: userMessage,
    });

    return {
      messages,
      system: systemMessage,
    };
  }

  /**
   * OpenAI API ì‘ë‹µì—ì„œ ì½˜í…ì¸  ì¶”ì¶œ
   */
  extractResponseContent(response) {
    // ì˜¤ë¥˜ ì‘ë‹µ ì²˜ë¦¬
    if (response.error) {
      throw new Error(`OpenAI API Error: ${response.error.message || response.error.type || 'Unknown error'}`);
    }

    // ì •ìƒ ì‘ë‹µ í™•ì¸
    if (!response.choices || response.choices.length === 0) {
      console.error('Invalid OpenAI response:', response);
      throw new Error('No response choices available');
    }

    const choice = response.choices[0];
    if (!choice.message || !choice.message.content) {
      console.error('Invalid choice format:', choice);
      throw new Error('Invalid response format');
    }

    return choice.message.content.trim();
  }

  /**
   * Claude API ì‘ë‹µì—ì„œ ì½˜í…ì¸  ì¶”ì¶œ
   */
  extractClaudeResponseContent(response) {
    if (!response.content || response.content.length === 0) {
      throw new Error('No response content available');
    }

    const content = response.content[0];
    if (!content.text) {
      throw new Error('Invalid response format');
    }

    return content.text.trim();
  }

  /**
   * Mock ì‘ë‹µ ìƒì„± (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
   */
  generateMockResponse() {
    const mockResponses = [
      `ì•ˆë…•í•˜ì„¸ìš”! ğŸ‘‹ ë²—ì…ë‹ˆë‹¤.
      Mock ëª¨ë“œë¡œ ì‹¤í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.

**ê°ì • íšŒë³µì„ ìœ„í•œ ì¡°ì–¸:**

ì§€ê¸ˆ ì´ë ‡ê²Œ ë§ë¡œ í’€ì–´ë‚´ëŠ” ê²ƒë§Œìœ¼ë¡œë„ í° ì§„ì „ì´ì—ìš”. 
ë•Œë¡œëŠ” ëª¨ë“  ê²ƒì´ ë¬´ê²ê²Œ ëŠê»´ì§ˆ ìˆ˜ ìˆì§€ë§Œ, 
ê·¸ ë¬´ê±°ì›€ì„ ì¸ì •í•˜ê³  ë°›ì•„ë“¤ì´ëŠ” ê²ƒì´ ì²« ë²ˆì§¸ ë‹¨ê³„ì…ë‹ˆë‹¤.

ì˜¤ëŠ˜ í•˜ë£¨ë„ ìˆ˜ê³ í–ˆì–´ìš”. ğŸŒŸ`,

      `ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”! ğŸ¤”

**ê°ì • íšŒë³µì˜ í•µì‹¬:**

1. **ì¸ì •í•˜ê¸°**: ì§€ê¸ˆì˜ ê°ì •ì„ ìˆëŠ” ê·¸ëŒ€ë¡œ ë°›ì•„ë“¤ì´ê¸°
2. **ì´í•´í•˜ê¸°**: ì´ ê°ì •ì´ ì™œ ìƒê²¼ëŠ”ì§€ íƒêµ¬í•˜ê¸°
3. **ì‹¤ì²œí•˜ê¸°**: ì‘ì€ í–‰ë™ìœ¼ë¡œ ë³€í™” ì‹œì‘í•˜ê¸°

ì–´ë–¤ ë¶€ë¶„ì—ì„œ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”? 
ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ì£¼ì‹œë©´ ë§ì¶¤í˜• ì¡°ì–¸ì„ ë“œë¦´ê²Œìš”! ğŸ’¡`,
    ];

    return mockResponses[Math.floor(Math.random() * mockResponses.length)];
  }

  /**
   * API ì‚¬ìš©ëŸ‰ ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹…ìš©)
   */
  getUsageInfo(response) {
    return response.usage || {
      prompt_tokens: 0,
      completion_tokens: 0,
      total_tokens: 0,
    };
  }
} 